{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu4pHSpyEA2i"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langchain deeplake openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import DeepLake\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = ''\n",
        "embeddigns = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "Pl80Cut6Ecpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!activeloop login -t -----------"
      ],
      "metadata": {
        "id": "FzAbb0oCEqci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "root_dir = './the-algorithm-main'\n",
        "docs = []\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "  for file in filenames:\n",
        "    try:\n",
        "      loader = TextLoader(os.path.join(dirpath, file), encoding = 'utf-8')\n",
        "      docs.extend(loader.load_and_split())\n",
        "    except Exception as e:\n",
        "      pass"
      ],
      "metadata": {
        "id": "cdkkyvWRFm0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlay=0)\n",
        "texts = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "didni3myG0RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = DeepLake.from_documents(texts, embeddings, dataset_path = \"hub://mg/twitter-algorithm\")"
      ],
      "metadata": {
        "id": "nauNb65ZHJti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = DeepLake(dataset_path = \"hub://mg/twitter-algorithm\", read_only=True, embedding_function = embeddings)"
      ],
      "metadata": {
        "id": "3iiyjG3WHdK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retreiver = db.as_retreiver()\n",
        "retreiver.search_kwargs['distance_metric'] = 'cos'\n",
        "retreiver.search_kwargs['fetch_k'] = 100\n",
        "retreiver.search_kwargs['maximal_marginal_relevance'] = True\n",
        "retreiver.search_kwargs['k'] = 20\n"
      ],
      "metadata": {
        "id": "ZZAmJkNcHqT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "model = ChatOpenAI(model='gpt-3.5-turbo')\n",
        "qa = ConversationalRetrievalChain.from_llm(model, retriever = retriever)"
      ],
      "metadata": {
        "id": "7ayPZGQMIQDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    'What does setup.py code do ?'\n",
        "]\n",
        "\n",
        "chat_history=[]\n",
        "\n",
        "for q in questions:\n",
        "  result = qa({\"question\":q, \"chat_history\":chat_history})\n",
        "  chat_history.append((q, result['answer']))\n",
        "  print(f\"-> **Question**:{q} \\n\")\n",
        "  print(f\"**Answer**: {result['answer']} \\n\")"
      ],
      "metadata": {
        "id": "lOkKlACQIv6k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}